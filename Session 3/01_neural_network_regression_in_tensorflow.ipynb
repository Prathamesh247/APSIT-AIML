{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/01_neural_network_regression_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xpVdMtKw6X4"
      },
      "source": [
        "## A larger example\n",
        "\n",
        "Alright, we've seen the fundamentals of building neural network regression models in TensorFlow.\n",
        "\n",
        "Let's step it up a notch and build a model for a more feature rich dataset.\n",
        "\n",
        "More specifically we're going to try predict the cost of medical insurance for individuals based on a number of different parameters such as, `age`, `sex`, `bmi`, `children`, `smoking_status` and `residential_region`.\n",
        "\n",
        "To do, we'll leverage the pubically available [Medical Cost dataset](https://www.kaggle.com/mirichoi0218/insurance) available from Kaggle and [hosted on GitHub](https://github.com/stedy/Machine-Learning-with-R-datasets/blob/master/insurance.csv).\n",
        "\n",
        "> ðŸ”‘ **Note:** When learning machine learning paradigms, you'll often go through a series of foundational techniques and then practice them by working with open-source datasets and examples. Just as we're doing now, learn foundations, put them to work with different problems. Every time you work on something new, it's a good idea to search for something like \"problem X example with Python/TensorFlow\" where you substitute X for your problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "WWK1LBxapgc2",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "JrnTr5N9blFo",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QtXPN7cfb4Nm",
        "outputId": "d859454e-45c9-4e6a-e919-65edf4cd139b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out the insurance dataset\n",
        "insurance.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s55oIsYv0KkZ"
      },
      "source": [
        "We're going to have to turn the non-numerical columns into numbers (because a neural network can't handle non-numerical inputs).\n",
        "\n",
        "To do so, we'll use the [`get_dummies()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) method in pandas.\n",
        "\n",
        "It converts categorical variables (like the `sex`, `smoker` and `region` columns) into numerical variables using one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "MqM_BmPkdon8",
        "outputId": "c6a4b1bf-3042-4702-bf7f-bce155e64310",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Turn all categories into numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head() # view the converted columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOHoPzgqgZPq"
      },
      "source": [
        "Now we'll split data into features (`X`) and labels (`y`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "W_EGj3FxhkAb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Create X & y values\n",
        "X = insurance_one_hot.drop(\"charges\", axis=1)\n",
        "y = insurance_one_hot[\"charges\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "-QQFJmDn5ATV",
        "outputId": "eb53df6b-4461-4251-f1c7-47cf81c99da7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View features\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kudhkM-0giS1"
      },
      "source": [
        "And create training and test sets. We could do this manually, but to make it easier, we'll leverage the already available [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function available from Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "WPGZGk0jhxCZ",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.2, \n",
        "                                                    random_state=42) # set random state for reproducible splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8wEC0FPglnN"
      },
      "source": [
        "Now we can build and fit a model (we'll make it the same as `model_2`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCXTmz6oh_T6",
        "outputId": "da476651-b453-4465-d8ee-9c16961b8ce1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8868.5918 - mae: 8868.5918\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7887.1606 - mae: 7887.1606\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7537.0947 - mae: 7537.0947\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7859.4346 - mae: 7859.4346\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7639.6699 - mae: 7639.6699\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7578.0850 - mae: 7578.0850\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7514.6177 - mae: 7514.6177\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7694.1338 - mae: 7694.1338\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7595.9136 - mae: 7595.9136\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7735.9116 - mae: 7735.9116\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7444.4189 - mae: 7444.4189\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7678.0337 - mae: 7678.0337\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7681.5840 - mae: 7681.5840\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7702.2842 - mae: 7702.2842\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7585.8921 - mae: 7585.8921\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7689.5356 - mae: 7689.5356\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7509.2036 - mae: 7509.2036\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7695.0083 - mae: 7695.0083\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7669.3740 - mae: 7669.3740\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7901.1362 - mae: 7901.1362\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7552.4814 - mae: 7552.4814\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7844.9961 - mae: 7844.9961\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7642.2485 - mae: 7642.2485\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7515.3081 - mae: 7515.3081\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7678.3506 - mae: 7678.3506\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7653.0269 - mae: 7653.0269\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7559.5449 - mae: 7559.5449\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7459.9404 - mae: 7459.9404\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7618.6177 - mae: 7618.6177\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7628.6255 - mae: 7628.6255\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7540.4893 - mae: 7540.4893\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7486.0186 - mae: 7486.0186\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7418.6646 - mae: 7418.6646\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7480.7319 - mae: 7480.7319\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7615.3115 - mae: 7615.3115\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7566.7896 - mae: 7566.7896\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7661.0879 - mae: 7661.0879\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7522.6816 - mae: 7522.6816\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7556.0718 - mae: 7556.0718\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7433.5669 - mae: 7433.5669\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7722.4312 - mae: 7722.4312\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7344.2700 - mae: 7344.2700\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7597.4331 - mae: 7597.4331\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7338.0132 - mae: 7338.0132\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7510.3467 - mae: 7510.3467\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7413.5801 - mae: 7413.5801\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7451.0391 - mae: 7451.0391\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7340.5381 - mae: 7340.5381\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7481.9976 - mae: 7481.9976\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7468.2842 - mae: 7468.2842\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7411.3408 - mae: 7411.3408\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7460.0796 - mae: 7460.0796\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7601.6606 - mae: 7601.6606\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7241.2549 - mae: 7241.2549\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7539.6953 - mae: 7539.6953\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7293.2012 - mae: 7293.2012\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7417.9731 - mae: 7417.9731\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7353.0625 - mae: 7353.0625\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7643.8247 - mae: 7643.8247\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7410.4004 - mae: 7410.4004\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7612.8330 - mae: 7612.8330\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7387.9087 - mae: 7387.9087\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7359.5605 - mae: 7359.5605\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7109.0884 - mae: 7109.0884\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7396.3223 - mae: 7396.3223\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.8613 - mae: 7179.8613\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7289.7710 - mae: 7289.7710\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7523.6973 - mae: 7523.6973\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7442.6157 - mae: 7442.6157\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7673.4834 - mae: 7673.4834\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7276.0337 - mae: 7276.0337\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7246.3721 - mae: 7246.3721\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7372.0713 - mae: 7372.0713\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7512.0762 - mae: 7512.0762\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7269.7437 - mae: 7269.7437\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7199.5039 - mae: 7199.5039\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7261.2920 - mae: 7261.2920\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7185.7627 - mae: 7185.7627\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7301.7495 - mae: 7301.7495\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7002.6309 - mae: 7002.6309\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7289.1357 - mae: 7289.1357\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7155.3945 - mae: 7155.3945\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7475.1709 - mae: 7475.1709\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7387.3672 - mae: 7387.3672\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7289.9458 - mae: 7289.9458\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7268.0942 - mae: 7268.0942\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7238.5869 - mae: 7238.5869\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7201.7354 - mae: 7201.7349\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7538.0757 - mae: 7538.0757\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6967.1187 - mae: 6967.1187\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7314.1299 - mae: 7314.1299\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7192.3115 - mae: 7192.3115\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7530.8770 - mae: 7530.8770\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7187.3579 - mae: 7187.3579\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7561.5635 - mae: 7561.5635\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7263.4648 - mae: 7263.4648\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7146.2896 - mae: 7146.2896\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7247.9238 - mae: 7247.9238\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7200.6694 - mae: 7200.6694\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7301.6870 - mae: 7301.6870\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8dedf0cad0>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a new model (same as model_2)\n",
        "insurance_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer=tf.keras.optimizers.SGD(),\n",
        "                        metrics=['mae'])\n",
        "\n",
        "# Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1U7LqpKid0r",
        "outputId": "0e322c1b-6c8a-49cd-f724-67afc65bba7f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 8628.2393 - mae: 8628.2393\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[8628.2392578125, 8628.2392578125]"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the results of the insurance model\n",
        "insurance_model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9doNDToqDru"
      },
      "source": [
        "Our model didn't perform very well, let's try a bigger model.\n",
        "\n",
        "We'll try 3 things:\n",
        "- Increasing the number of layers (2 -> 3).\n",
        "- Increasing the number of units in each layer (except for the output layer).\n",
        "- Changing the optimizer (from SGD to Adam).\n",
        "\n",
        "Everything else will stay the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "W59EqfqYimnR",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Add an extra layer and increase number of units\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100), # 100 units\n",
        "  tf.keras.layers.Dense(10), # 10 units\n",
        "  tf.keras.layers.Dense(1) # 1 unit (important for output layer)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(), # Adam works but SGD doesn't \n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model and save the history (we can plot this)\n",
        "history = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9IbYWnOqmoT",
        "outputId": "eab558fc-8905-42fe-89b4-eb6576eae14c",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate our larger model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9Rf3NosqriS"
      },
      "source": [
        "Much better! Using a larger model and the Adam optimizer results in almost half the error as the previous model.\n",
        "\n",
        "> ðŸ”‘ **Note:** For many problems, the [Adam optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) is a great starting choice. See Andrei Karpathy's \"Adam is safe\" point from [*A Recipe for Training Neural Networks*](http://karpathy.github.io/2019/04/25/recipe/) for more. \n",
        "\n",
        "Let's check out the loss curves of our model, we should see a downward trend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "9SE55ANojcF_",
        "outputId": "1c145cb3-71ef-4f0f-bf8e-26e95f3398f0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot history (also known as a loss curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckHqtn0srQ5q"
      },
      "source": [
        "From this, it looks like our model's loss (and MAE) were both still decreasing (in our case, MAE and loss are the same, hence the lines in the plot overlap eachother).\n",
        "\n",
        "What this tells us is the loss might go down if we try training it for longer.\n",
        "\n",
        "> ðŸ¤” **Question:** How long should you train for? \n",
        "\n",
        "> It depends on what problem you're working on. Sometimes training won't take very long, other times it'll take longer than you expect. A common method is to set your model training for a very long time (e.g. 1000's of epochs) but set it up with an [EarlyStopping callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) so it stops automatically when it stops improving. We'll see this in another module.\n",
        "\n",
        "Let's train the same model as above for a little longer. We can do this but calling fit on it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Ucs62jV8jl6N",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Try training for a little longer (100 more epochs)\n",
        "history_2 = insurance_model_2.fit(X_train, y_train, epochs=100, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2FZA1z1sxxs"
      },
      "source": [
        "How did the extra training go?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxtiYB3qs0PZ",
        "outputId": "9d479dec-66d0-4e02-9b2f-316910fa7b95",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3494.7285 - mae: 3494.7285\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(3494.728515625, 3494.728515625)"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model trained for 200 total epochs\n",
        "insurance_model_2_loss, insurance_model_2_mae = insurance_model_2.evaluate(X_test, y_test)\n",
        "insurance_model_2_loss, insurance_model_2_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzUySYEOs-O_"
      },
      "source": [
        "Boom! Training for an extra 100 epochs we see about a 10% decrease in error.\n",
        "\n",
        "How does the visual look?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "BtYKSLeQjuzL",
        "outputId": "49c03b0b-a5ce-49ac-b7e8-4f9e69ea17b9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the model trained for 200 total epochs loss curves\n",
        "pd.DataFrame(history_2.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\"); # note: epochs will only show 100 since we overrid the history variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS8xYkvIuVZZ"
      },
      "source": [
        "## Preprocessing data (normalization and standardization)\n",
        "\n",
        "A common practice when working with neural networks is to make sure all of the data you pass to them is in the range 0 to 1.\n",
        "\n",
        "This practice is called **normalization** (scaling all values from their original range to, e.g. between 0 and 100,000 to be between 0 and 1).\n",
        "\n",
        "There is another process call **standardization** which converts all of your data to unit variance and 0 mean.\n",
        "\n",
        "These two practices are often part of a preprocessing pipeline (a series of functions to prepare your data for use with neural networks).\n",
        "\n",
        "Knowing this, some of the major steps you'll take to preprocess your data for a neural network include:\n",
        "* Turning all of your data to numbers (a neural network can't handle strings).\n",
        "* Making sure your data is in the right shape (verifying input and output shapes).\n",
        "* [**Feature scaling**](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler):\n",
        "    * Normalizing data (making sure all values are between 0 and 1). This is done by subtracting the minimum value then dividing by the maximum value minus the minmum. This is also referred to as min-max scaling.\n",
        "    * Standardization (making sure all values have a mean of 0 and a variance of 1). This is done by substracting the mean value from the target feature and then dividing it by the standard deviation.\n",
        "    * Which one should you use?\n",
        "      * **With neural networks you'll tend to favour normalization** as they tend to prefer values between 0 and 1 (you'll see this espcially with image processing), however, you'll often find a neural network can perform pretty well with minimal feature scaling.\n",
        "\n",
        "> ðŸ“– **Resource:** For more on preprocessing data, I'd recommend reading the following resources:\n",
        "* [Scikit-Learn's documentation on preprocessing data](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-data).\n",
        "* [Scale, Standardize or Normalize with Scikit-Learn by Jeff Hale](https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02).\n",
        "\n",
        "We've already turned our data into numbers using `get_dummies()`, let's see how we'd normalize it as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "9v7P20A2d7H6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read in the insurance dataset\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vir8UAIwlUOo",
        "outputId": "306bc0ed-8038-4822-b69e-c0181f5c8f88",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out the data\n",
        "insurance.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMQiNosg3J3"
      },
      "source": [
        "Now, just as before, we need to transform the non-numerical columns into numbers and this time we'll also be normalizing the numerical columns with different ranges (to make sure they're all between 0 and 1).\n",
        "\n",
        "To do this, we're going to use a few classes from Scikit-Learn:\n",
        "* [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) - build a multi-step data preprocessing function for the folllowing transformations:\n",
        "  * [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) - make sure all numerical columns are normalized (between 0 and 1).\n",
        "  * [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) - one hot encode the non-numerical columns.\n",
        "\n",
        "Let's see them in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "-x9JwbV0hqWh",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "# Create column transformer (this will help us normalize/preprocess our data)\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # get all values between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
        ")\n",
        "\n",
        "# Create X & y\n",
        "X = insurance.drop(\"charges\", axis=1)\n",
        "y = insurance[\"charges\"]\n",
        "\n",
        "# Build our train and test sets (use random state to ensure same split as before)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit column transformer on the training data only (doing so on test data would result in data leakage)\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScalar) and one hot encoding (OneHotEncoder)\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz58y3nPiBJ-"
      },
      "source": [
        "Now we've normalized it and one-hot encoding it, what does our data look like now?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VODt2YiziK45",
        "outputId": "0aacd372-5097-40d5-d27c-daf5cc32255a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age                19\n",
              "sex            female\n",
              "bmi              27.9\n",
              "children            0\n",
              "smoker            yes\n",
              "region      southwest\n",
              "Name: 0, dtype: object"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Non-normalized and non-one-hot encoded data example\n",
        "X_train.loc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMYDXdwUnNVt",
        "outputId": "793a3869-9588-4861-8923-ae8adbb530fc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "       0.        ])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Normalized and one-hot encoded example\n",
        "X_train_normal[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iI4KtfWib44"
      },
      "source": [
        "How about the shapes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFmxzqrWntj7",
        "outputId": "e13b80e2-e9c6-443b-8178-520113ced7b9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((1070, 11), (1070, 6))"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Notice the normalized/one-hot encoded shape is larger because of the extra columns\n",
        "X_train_normal.shape, X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MST951aYijTS"
      },
      "source": [
        "Our data is normalized and numerical, let's model it.\n",
        "\n",
        "We'll use the same model as `insurance_model_2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdHnIQqll83Y",
        "outputId": "2efbfe2f-b476-4f39-a35d-3a3f3c7fa81b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8df4a6da50>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Build the model (3 layers, 100, 10, 1 units)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(100),\n",
        "  tf.keras.layers.Dense(10),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer=tf.keras.optimizers.Adam(),\n",
        "                          metrics=['mae'])\n",
        "\n",
        "# Fit the model for 200 epochs (same as insurance_model_2)\n",
        "insurance_model_3.fit(X_train_normal, y_train, epochs=200, verbose=0) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DjwktO6jW41"
      },
      "source": [
        "Let's evaluate the model on normalized test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBcXZu9AnZfP",
        "outputId": "d42dbf4e-807b-4de2-c38c-b3cf2dbb5e70",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3171.5774 - mae: 3171.5774\n"
          ]
        }
      ],
      "source": [
        "# Evaulate 3rd model\n",
        "insurance_model_3_loss, insurance_model_3_mae = insurance_model_3.evaluate(X_test_normal, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlHro290jhtX"
      },
      "source": [
        "And finally, let's compare the results from `insurance_model_2` (trained on non-normalized data) and `insurance_model_3` (trained on normalized data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybZtnVlNjCJO",
        "outputId": "ef1d85b1-f6e5-4d54-9e9a-509040916288",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3494.728515625, 3171.577392578125)"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compare modelling results from non-normalized data and normalized data\n",
        "insurance_model_2_mae, insurance_model_3_mae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUttViY4jzi8"
      },
      "source": [
        "From this we can see normalizing the data results in 10% less error using the same model than not normalizing the data.\n",
        "\n",
        "This is **one of the main benefits of normalization: faster convergence time** (a fancy way of saying, your model gets to better results faster).\n",
        "\n",
        "`insurance_model_2` may have eventually achieved the same results as `insurance_model_3` if we left it training for longer. \n",
        "\n",
        "Also, the results may change if we were to alter the architectures of the models, e.g. more hidden units per layer or more layers.\n",
        "\n",
        "But since our main goal as neural network practitioners is to decrease the time between experiments, anything that helps us get better results sooner is a plus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhIPO_KqocHP"
      },
      "source": [
        "## ðŸ›  Exercises\n",
        "\n",
        "We've a covered a whole lot pretty quickly.\n",
        "\n",
        "So now it's time to have a **play around** with a few things and start to build up your intuition.\n",
        "\n",
        "I emphasise the words play around because that's very important. Try a few things out, run the code and see what happens.\n",
        "\n",
        "1. Create your own regression dataset (or make the one we created in \"Create data to view and fit\" bigger) and build fit a model to it.\n",
        "2. Try building a neural network with 4 Dense layers and fitting it to your own regression dataset, how does it perform?\n",
        "3. Try and improve the results we got on the insurance dataset, some things you might want to try include:\n",
        "  * Building a larger model (how does one with 4 dense layers go?).\n",
        "  * Increasing the number of units in each layer.\n",
        "  * Lookup the documentation of [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and find out what the first parameter is, what happens if you increase it by 10x?\n",
        "  * What happens if you train for longer (say 300 epochs instead of 200)? \n",
        "4. Import the [Boston pricing dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/boston_housing/load_data) from TensorFlow [`tf.keras.datasets`](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) and model it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyiHG2nubmu7"
      },
      "source": [
        "## ðŸ“– Extra curriculum\n",
        "\n",
        "If you're looking for extra materials relating to this notebook, I'd check out the following:\n",
        "\n",
        "* [MIT introduction deep learning lecture 1](https://youtu.be/njKP3FqW3Sk) - gives a great overview of what's happening behind all of the code we're running.\n",
        "* Reading: 1-hour of [Chapter 1 of Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html) by Michael Nielson - a great in-depth and hands-on example of the intuition behind neural networks.\n",
        "\n",
        "To practice your regression modelling with TensorFlow, I'd also encourage you to look through [Lion Bridge's collection of datasets](https://lionbridge.ai/datasets/) or [Kaggle's datasets](https://www.kaggle.com/data), find a regression dataset which sparks your interest and try to model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPJ5Dpbkicrqvik8JYM2rWb",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "01_neural_network_regression_in_tensorflow.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
